# -*- coding: utf-8 -*-
# ì´ íŒŒì¼ì€ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ë¡œë”© ë° ì˜ˆì¸¡ ë¡œì§ì„ ì „ë‹´í•©ë‹ˆë‹¤.

import os
import joblib
import numpy as np
import pandas as pd
from typing import Tuple
import pywt  # âœ… ì›¨ì´ë¸Œë › ì‚¬ìš©

# app.pyê°€ ì•„ë‹Œ ì—¬ê¸°ì„œ ì§ì ‘ schemasë¥¼ importí•©ë‹ˆë‹¤.
import schemas

# --- ëª¨ë¸/ì „ì²˜ë¦¬ê¸° íŒŒì¼ì„ ëª¨ë‘ ë¡œë“œ ---
base_dir = os.path.dirname(__file__)
model_dir = os.path.join(base_dir, "model")

# âœ… zero_center ì œê±°(ë¡œë“œ/ì‚¬ìš© X)
MODEL_PATHS = {
    "mlp": os.path.join(model_dir, "mlp_model_6input.pkl"),
    "scaler": os.path.join(model_dir, "scaler.pkl"),  # Scalerë¥¼ ë³„ë„ë¡œ ë¡œë“œ
    "label_encoder": os.path.join(model_dir, "label_encoder_6input.pkl"),
    "soft_iron": os.path.join(model_dir, "soft_iron_matrix.pkl"),
    "hard_iron": os.path.join(model_dir, "bias.pkl"),
}

models = {}
MODEL_LOADED = False
FEATURE_COLS = None
try:
    for name, path in MODEL_PATHS.items():
        models[name] = joblib.load(path)
        print(f"âœ… ëª¨ë¸ ì»´í¬ë„ŒíŠ¸ ë¡œë“œ ì™„ë£Œ: {os.path.basename(path)}")
    MODEL_LOADED = True
    # (ìœ ì§€) íŠ¹ì§• ì»¬ëŸ¼: 6-input
    FEATURE_COLS = ['Mag_X', 'Mag_Y', 'Mag_Z', 'Ori_X', 'Ori_Y', 'Ori_Z']
    print("ðŸš€ ëª¨ë“  ëª¨ë¸ ì»´í¬ë„ŒíŠ¸(6-input)ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
except (FileNotFoundError, KeyError) as e:
    print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")

# --- ì™¸ë¶€(app.py)ì—ì„œ ì‚¬ìš©í•  í•¨ìˆ˜ë“¤ ---

def get_model_status() -> dict:
    """ëª¨ë¸ì˜ ë¡œë“œ ìƒíƒœì™€ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return {
        "status": "ok" if MODEL_LOADED else "error",
        "model_loaded": MODEL_LOADED,
        "model_name": "MLP 6-input (Hard/Soft-Iron + Wavelet + Scaler)",  # ì´ë¦„ ê°±ì‹ 
        "feature_cols": FEATURE_COLS if MODEL_LOADED else None,
    }

def extract_location_id(label_str):
    """ë¼ë²¨ì—ì„œ ìœ„ì¹˜ IDë§Œ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ (ê¸°ì¡´ê³¼ ë™ì¼)"""
    try:
        return int(str(label_str).split('_')[0])
    except (ValueError, IndexError):
        try:
            return int(label_str)
        except:
            return 0

def run_prediction(data: schemas.SensorInput) -> Tuple[int, list, list]:
    """
    6-input ëª¨ë¸ì— ë§žê²Œ ìˆ˜ë™ ì „ì²˜ë¦¬ ë° ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    ìˆœì„œ: Hard-Iron â†’ Soft-Iron â†’ Wavelet(ìš”ì²­ê³¼ 100% ë™ì¼ êµ¬í˜„) â†’ Scaler â†’ MLP
    """
    if not MODEL_LOADED:
        raise RuntimeError("Model components are not loaded properly.")

    # 1. ìž…ë ¥ ë°ì´í„°ë¥¼ Pandas DataFrameìœ¼ë¡œ ë³€í™˜
    feature_df = pd.DataFrame([data.model_dump()], columns=FEATURE_COLS)

    # (ì‚­ì œ) ìžê¸°ìž¥ í¬ê¸°(Mag_abs) ê³„ì‚° ë¡œì§ ì œê±°

    # 3. Hard-Iron ë³´ì •
    for col in ['Mag_X', 'Mag_Y', 'Mag_Z']:
        feature_df[col] = feature_df[col].astype(float) - float(models["hard_iron"][col])

    # 4. Soft-Iron ë³´ì •
    mag_data = feature_df[['Mag_X', 'Mag_Y', 'Mag_Z']].values
    feature_df[['Mag_X', 'Mag_Y', 'Mag_Z']] = np.dot(mag_data, models["soft_iron"].T)

    # ================================
    # âœ… ì›¨ì´ë¸Œë › Denoising (ìš”ì²­ë¬¸ê³¼ 100% ë™ì¼)
    # ================================
    # í˜¸ì¶œë¶€ê¹Œì§€ ë™ì¼í•˜ê²Œ ë§žì¶”ê¸° ìœ„í•´ aliasì™€ ë¦¬ìŠ¤íŠ¸ëª…ì„ ë™ì¼í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤.
    df = feature_df
    mag_cols = ['Mag_X', 'Mag_Y', 'Mag_Z']

    # -------------------------------
    # 4ï¸âƒ£ ì›¨ì´ë¸Œë › Denoising (Magnetometer)
    #    db4, level=3, soft-threshold(Donoho universal)
    # -------------------------------
    def wavelet_denoise(signal, wavelet='db4', level=3, mode='soft'):
        # DWT
        coeffs = pywt.wavedec(signal, wavelet=wavelet, level=level)
        # ë…¸ì´ì¦ˆ í‘œì¤€íŽ¸ì°¨ ì¶”ì • (ìµœìƒìœ„ detail ê³„ìˆ˜ì˜ median absolute deviation)
        sigma = np.median(np.abs(coeffs[-1])) / 0.6745 if len(coeffs[-1]) > 0 else 0.0
        if sigma == 0.0:
            return signal  # ë…¸ì´ì¦ˆ ì¶”ì • ë¶ˆê°€ ì‹œ ì›ì‹ í˜¸ ë°˜í™˜
        uthresh = sigma * np.sqrt(2 * np.log(len(signal)))
        # Approximation(A) ì œì™¸, Detail(D) ê³„ìˆ˜ë§Œ ìž„ê³„ê°’ ì ìš©
        denoised_coeffs = [coeffs[0]] + [
            pywt.threshold(c, value=uthresh, mode=mode) for c in coeffs[1:]
        ]
        recon = pywt.waverec(denoised_coeffs, wavelet=wavelet)
        # ê¸¸ì´ ë³´ì • (ê²½ê³„ ì²˜ë¦¬ë¡œ ê¸¸ì´ê°€ 1~2 ìƒ˜í”Œ ë‹¬ë¼ì§ˆ ìˆ˜ ìžˆìŒ)
        return recon[:len(signal)]

    for col in mag_cols:
        df[col] = wavelet_denoise(df[col].values, wavelet='db4', level=3, mode='soft')
    print("âœ… Wavelet Denoising ì™„ë£Œ")
    # ================================

    # (ì™„ì „ ì œê±°) Zero-Centering ë‹¨ê³„
    # for col in FEATURE_COLS:
    #     feature_df[col] -= models["zero_center"][col]

    # 6. ë°ì´í„° ìŠ¤ì¼€ì¼ë§
    scaled_features = models["scaler"].transform(feature_df)

    # 7. MLP ëª¨ë¸ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰
    mlp_model = models["mlp"]
    prediction_index = mlp_model.predict(scaled_features)[0]

    # ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼ì—ì„œ ì ‘ë¯¸ì‚¬ ì œê±°
    raw_prediction = models["label_encoder"].inverse_transform([prediction_index])[0]
    final_prediction = extract_location_id(raw_prediction)

    # 8. ì‹ ë¢°ë„ ë° Top-3 ê³„ì‚°
    top_results_for_logging, top_results_for_response = [], []

    if hasattr(mlp_model, "predict_proba"):
        probabilities = mlp_model.predict_proba(scaled_features)[0]
        num_candidates = min(len(probabilities), 15)
        top_indices = np.argsort(-probabilities)[:num_candidates]
        raw_top_labels = models["label_encoder"].inverse_transform(top_indices)
        top_probs = probabilities[top_indices]

        seen_locations = set()
        unique_results = []

        for raw_label, prob in zip(raw_top_labels, top_probs):
            location_id = extract_location_id(raw_label)
            if location_id not in seen_locations:
                seen_locations.add(location_id)
                unique_results.append((location_id, float(prob)))
                if len(unique_results) >= 3:
                    break

        while len(unique_results) < 3:
            unique_results.append((0, 0.0))

        top_results_for_logging = unique_results[:3]
        top_results_for_response = unique_results[:3]

    return final_prediction, top_results_for_logging, top_results_for_response
