# -*- coding: utf-8 -*-
"""
FastAPI ì„œë²„: Scikit-learn Pipeline ìœ„ì¹˜ ì˜ˆì¸¡ + ì‚¬ìš©ì ê´€ë¦¬ + ì˜ˆì¸¡ ìœ„ì¹˜ ì •ë³´ (v5.0)
- ìƒˆë¡œìš´ 6-Input MLP ëª¨ë¸ ë° ë‹¤ë‹¨ê³„ ë³´ì • íŒŒì´í”„ë¼ì¸ ì ìš©
"""
import os
import joblib
import numpy as np
from fastapi import FastAPI, Depends
from sqlalchemy.orm import Session
from typing import List

# --- ë¼ìš°í„°, DB, ìŠ¤í‚¤ë§ˆ, CRUD í•¨ìˆ˜ import ---
from database import engine, Base, get_db
from user_router import router as user_router
from favorites_router import router as favorites_router
from locations_router import router as locations_router
import crud
import schemas

# ì„œë²„ ì‹œì‘ ì‹œ ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìƒì„±
Base.metadata.create_all(bind=engine)

# ğŸ”½ [ìˆ˜ì •] ìƒˆë¡œìš´ ëª¨ë¸ 5ê°œ ë¡œë“œ ---
# ------------------------------------
base_dir = os.path.dirname(__file__)
model_dir = os.path.join(base_dir, "model")

# ëª¨ë¸ íŒŒì¼ ê²½ë¡œ ì •ì˜
MODEL_PATHS = {
    "mlp": os.path.join(model_dir, "mlp_model_6input.pkl"),
    "scaler": os.path.join(model_dir, "scaler.pkl"),
    "zero_center": os.path.join(model_dir, "zero_center_means.pkl"),
    "soft_iron": os.path.join(model_dir, "soft_iron_matrix.pkl"),
    "hard_iron": os.path.join(model_dir, "bias.pkl")
}

# ëª¨ë¸ ì»´í¬ë„ŒíŠ¸ë“¤ì„ ë‹´ì„ ë”•ì…”ë„ˆë¦¬
models = {}
try:
    for name, path in MODEL_PATHS.items():
        models[name] = joblib.load(path)
        print(f"âœ… ëª¨ë¸ ì»´í¬ë„ŒíŠ¸ ë¡œë“œ ì™„ë£Œ: {os.path.basename(path)}")
    MODEL_LOADED = True
    # í•™ìŠµ ì½”ë“œì— ëª…ì‹œëœ 6ê°œì˜ í”¼ì²˜
    FEATURE_COLS = ['Mag_X', 'Mag_Y', 'Mag_Z', 'Ori_X', 'Ori_Y', 'Ori_Z']
    print("ğŸš€ ëª¨ë“  ëª¨ë¸ ì»´í¬ë„ŒíŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
except (FileNotFoundError, KeyError) as e:
    print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    MODEL_LOADED = False
# ------------------------------------

# ğŸ”½ [ìˆ˜ì •] ìƒˆë¡œìš´ ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸ Helper í•¨ìˆ˜ ---
def _run_new_prediction_pipeline(payload: schemas.SensorInput, top_k: int = 1):
    """ìƒˆë¡œìš´ ëª¨ë¸ì˜ ë‹¤ë‹¨ê³„ ë³´ì • ë° ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    
    # 1. ì…ë ¥ ë°ì´í„°ë¥¼ NumPy ë°°ì—´ë¡œ ë³€í™˜
    mag_data = np.array([[payload.Mag_X, payload.Mag_Y, payload.Mag_Z]])
    ori_data = np.array([[payload.Ori_X, payload.Ori_Y, payload.Ori_Z]])

    # 2. ìê¸°ì¥ ì„¼ì„œ ë°ì´í„° ë³´ì • (Calibration)
    #    - Zero-centering -> Soft-iron correction -> Hard-iron correction
    mag_centered = mag_data - models["zero_center"]
    mag_soft_corrected = np.dot(mag_centered, models["soft_iron"])
    mag_calibrated = mag_soft_corrected - models["hard_iron"]

    # 3. ìµœì¢… í”¼ì²˜ ë²¡í„° ìƒì„± (ë³´ì •ëœ Mag 3ì¶• + Ori 3ì¶•)
    feature_vector = np.concatenate((mag_calibrated, ori_data), axis=1)

    # 4. ë°ì´í„° ìŠ¤ì¼€ì¼ë§ (StandardScaler)
    scaled_features = models["scaler"].transform(feature_vector)

    # 5. MLP ëª¨ë¸ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰
    mlp_model = models["mlp"]
    prediction = int(mlp_model.predict(scaled_features)[0])
    
    # 6. ì‹ ë¢°ë„(Confidence) ë° Top-K ê²°ê³¼ ê³„ì‚°
    confidence, top_k_list = None, None
    if hasattr(mlp_model, "predict_proba"):
        probabilities = mlp_model.predict_proba(scaled_features)
        confidence = float(np.max(probabilities))
        if top_k > 1:
            idx_sorted = np.argsort(-probabilities, axis=1)[:, :top_k]
            # label_encoderê°€ ì—†ìœ¼ë¯€ë¡œ ì •ìˆ˜ ì¸ë±ìŠ¤ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
            top_k_list = [f"{int(cls)} ({probabilities[0, cls]:.4f})" for cls in idx_sorted[0]]

    return prediction, confidence, top_k_list
# ----------------------------------------------------

# --- FastAPI ì•± ì´ˆê¸°í™” ë° ë¼ìš°í„° ë“±ë¡ ---
app = FastAPI(
    title="Midas API - ì‹¤ë‚´ ìœ„ì¹˜ ì˜ˆì¸¡ ë° ì‚¬ìš©ì ì„œë¹„ìŠ¤ (6-Input MLP)",
    description="ìƒˆë¡œìš´ 6-Input MLP ëª¨ë¸ê³¼ ìê¸°ì¥ ë³´ì • íŒŒì´í”„ë¼ì¸ì´ ì ìš©ëœ API ì„œë²„ì…ë‹ˆë‹¤.",
    version="5.0.0",
)
app.include_router(user_router, prefix="/users", tags=["users"])
app.include_router(favorites_router, prefix="/favorites", tags=["favorites"])
app.include_router(locations_router, prefix="/locations", tags=["Predicted Locations"])

# --- API Endpoints ---
@app.get("/health", summary="ì„œë²„ ìƒíƒœ í™•ì¸")
def health():
    return {
        "status": "ok" if MODEL_LOADED else "error",
        "model_loaded": MODEL_LOADED,
        "model_name": "MLPClassifier (6-Input with Calibration)",
        "feature_cols": FEATURE_COLS if MODEL_LOADED else None,
    }

@app.post("/predict", response_model=schemas.ModelOutput, summary="ì„¼ì„œ ë°ì´í„°ë¡œ ìœ„ì¹˜ ì˜ˆì¸¡")
def predict(data: schemas.SensorInput, db: Session = Depends(get_db)):
    if not MODEL_LOADED:
        return schemas.ModelOutput(
            prediction=-1, confidence=0.0, location_details=None,
            top_k_results=["Error: Model components are not loaded."]
        )
    
    # 1. [ìˆ˜ì •] ìƒˆë¡œìš´ ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    prediction_result, confidence_score, top_k_list = _run_new_prediction_pipeline(data, top_k=data.top_k)
    
    # 2. DBì—ì„œ ìœ„ì¹˜ ì •ë³´ ì¡°íšŒ (ê¸°ì¡´ê³¼ ë™ì¼)
    location_info_db = crud.get_predicted_location(db, location_id=prediction_result)
    
    location_details_schema = None
    if location_info_db:
        location_details_schema = schemas.PredictedLocation.model_validate(location_info_db)

    # 3. ìµœì¢… ì‘ë‹µ ìƒì„± (ê¸°ì¡´ê³¼ ë™ì¼)
    return schemas.ModelOutput(
        prediction=prediction_result,
        confidence=confidence_score,
        location_details=location_details_schema,
        top_k_results=top_k_list
    )

@app.get("/", summary="API ì •ë³´")
def root():
    return {
        "message": "Full-featured Sensor Prediction API with User Management",
        "version": "5.0.0",
        "model_type": "6-Input MLPClassifier with Calibration Pipeline",
        # (ê¸°ëŠ¥ ì„¤ëª…ì€ ê¸°ì¡´ê³¼ ë™ì¼)
    }

