# -*- coding: utf-8 -*-
# ì˜¨ë¼ì¸ ì „ì²˜ë¦¬(ìœˆë„ìš°+ì›¨ì´ë¸Œë ›)ì™€ 100% ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ì‹¤ì‚¬ìš© ì˜ˆì¸¡

import os
import joblib
import numpy as np
from typing import Tuple, Optional, Dict, Any
import pywt
from collections import deque

import schemas  # app.pyê°€ ì•„ë‹Œ ì—¬ê¸°ì„œ ì§ì ‘ import

# -------------------------------
# ê²½ë¡œ ë° íŒŒì¼
# -------------------------------
BASE_DIR = os.path.dirname(__file__)
MODEL_DIR = os.path.join(BASE_DIR, "model")

MODEL_PATHS = {
    "mlp": os.path.join(MODEL_DIR, "mlp_model_6input.pkl"),
    "scaler": os.path.join(MODEL_DIR, "scaler.pkl"),
    "label_encoder": os.path.join(MODEL_DIR, "label_encoder_6input.pkl"),
    "soft_iron": os.path.join(MODEL_DIR, "soft_iron_matrix.pkl"),
    "hard_iron": os.path.join(MODEL_DIR, "bias.pkl"),
    "preproc_params": os.path.join(MODEL_DIR, "preproc_params.pkl"),
    "wavelet_sigma": os.path.join(MODEL_DIR, "wavelet_sigma.pkl"),  # fixed ì „ëµ ì‹œ
}

# -------------------------------
# ê¸°ë³¸ íŒŒë¼ë¯¸í„° (preproc_params ì—†ì„ ë•Œ)
# -------------------------------
DEFAULT_PARAMS = {
    "wavelet": "db4",
    "level": 3,
    "thresh_mode": "soft",
    "window_size": 256,
    "hop_size": 1,
    "border_mode": "symmetric",
    "strategy": "adaptive",        # 'adaptive' ë˜ëŠ” 'fixed'
    "warmup_policy": "pad",        # 'pad' | 'wait' | 'passthrough' | 'ratio'
    "min_fill_ratio": 0.5,         # warmup_policy='ratio'ì—ì„œ ì‚¬ìš©
}

MAG_COLS = ["Mag_X", "Mag_Y", "Mag_Z"]
ORI_COLS = ["Ori_X", "Ori_Y", "Ori_Z"]
FEATURE_COLS = MAG_COLS + ORI_COLS

# -------------------------------
# ë¡œë“œ
# -------------------------------
models: Dict[str, Any] = {}
PREPROC_PARAMS = DEFAULT_PARAMS.copy()
FIXED_SIGMA = None
BUFFERS: Dict[str, deque] = {}
MODEL_LOADED = False

try:
    # í•„ìˆ˜/ì„ íƒ ëª¨ë¸ ë¡œë“œ
    for k, p in MODEL_PATHS.items():
        if os.path.exists(p):
            models[k] = joblib.load(p)
            print(f"âœ… ë¡œë“œ: {os.path.basename(p)}")

    required = ["mlp", "scaler", "label_encoder", "soft_iron", "hard_iron"]
    if not all(k in models for k in required):
        missing = [k for k in required if k not in models]
        raise FileNotFoundError(f"í•„ìˆ˜ ëª¨ë¸ íŒŒì¼ ëˆ„ë½: {missing}")

    # ì „ì²˜ë¦¬ íŒŒë¼ë¯¸í„°
    if "preproc_params" in models:
        PREPROC_PARAMS.update(models["preproc_params"])
        print("âœ… ì „ì²˜ë¦¬ íŒŒë¼ë¯¸í„° ì ìš©:", PREPROC_PARAMS)
    else:
        print("â„¹ï¸ preproc_params.pkl ì—†ìŒ â†’ ê¸°ë³¸ íŒŒë¼ë¯¸í„° ì‚¬ìš©:", PREPROC_PARAMS)

    # fixed ì „ëµì´ë©´ ì „ì—­ ì„ê³„ ì‚¬ìš©
    if PREPROC_PARAMS.get("strategy", "adaptive") == "fixed" and "wavelet_sigma" in models:
        FIXED_SIGMA = models["wavelet_sigma"]
        print("âœ… wavelet_sigma ì ìš©(ê³ ì • ì„ê³„):",
              {k: {"uthresh": v.get("uthresh", None)} for k, v in FIXED_SIGMA.items()})
    else:
        print("â„¹ï¸ adaptive ëª¨ë“œ ë˜ëŠ” wavelet_sigma ë¯¸ì¡´ì¬")

    # ì‹¤ì‹œê°„ ë²„í¼ ì¤€ë¹„
    BUFFERS = {c: deque(maxlen=int(PREPROC_PARAMS["window_size"])) for c in MAG_COLS}

    MODEL_LOADED = True
    print("ğŸš€ ëª¨ë“  ëª¨ë¸ ì»´í¬ë„ŒíŠ¸(6-input) ë¡œë“œ ì™„ë£Œ")
except Exception as e:
    print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")


# -------------------------------
# ìœ í‹¸
# -------------------------------
def get_model_status() -> dict:
    return {
        "status": "ok" if MODEL_LOADED else "error",
        "model_loaded": MODEL_LOADED,
        "model_name": "MLP 6-input (Hard/Soft-Iron + Windowed Wavelet + Scaler)",
        "feature_cols": FEATURE_COLS if MODEL_LOADED else None,
        "wavelet_strategy": PREPROC_PARAMS.get("strategy", None) if MODEL_LOADED else None,
        "window_size": PREPROC_PARAMS.get("window_size", None) if MODEL_LOADED else None,
        "warmup_policy": PREPROC_PARAMS.get("warmup_policy", None) if MODEL_LOADED else None,
    }


def extract_location_id(label_str):
    try:
        return int(str(label_str).split("_")[0])
    except (ValueError, IndexError):
        try:
            return int(label_str)
        except Exception:
            return 0


def _wavelet_denoise_window(x: np.ndarray, col_name: str) -> np.ndarray:
    """
    í•™ìŠµê³¼ ë™ì¼: db4/level/thresh_mode/border_mode.
    strategy=='fixed'ì´ë©´ ì €ì¥ëœ uthresh ì‚¬ìš©, ì•„ë‹ˆë©´ adaptive.
    """
    wavelet = PREPROC_PARAMS["wavelet"]
    level = int(PREPROC_PARAMS["level"])
    mode = PREPROC_PARAMS["thresh_mode"]
    border = PREPROC_PARAMS["border_mode"]

    coeffs = pywt.wavedec(x, wavelet=wavelet, level=level, mode=border)

    # uthresh ê²°ì •
    if PREPROC_PARAMS.get("strategy", "adaptive") == "fixed" and FIXED_SIGMA and FIXED_SIGMA.get(col_name):
        uthresh = float(FIXED_SIGMA[col_name].get("uthresh", 0.0))
        if uthresh <= 0:
            return x
    else:
        d = coeffs[-1]
        if len(d) == 0:
            return x
        sigma = np.median(np.abs(d)) / 0.6745
        if sigma == 0:
            return x
        uthresh = sigma * np.sqrt(2 * np.log(len(x)))

    den = [coeffs[0]] + [pywt.threshold(c, value=uthresh, mode=mode) for c in coeffs[1:]]
    y = pywt.waverec(den, wavelet=wavelet, mode=border)
    return y[:len(x)]


def _latest_value_with_warmup(col_name: str) -> float:
    """
    ë²„í¼(windows) ê¸°ë°˜ ì›¨ì´ë¸Œë › í›„ ìµœì‹  1ìƒ˜í”Œ ë°˜í™˜.
    warmup ì •ì±…: pad | wait | passthrough | ratio
    """
    window_size = int(PREPROC_PARAMS["window_size"])
    policy = PREPROC_PARAMS.get("warmup_policy", "pad")
    ratio = float(PREPROC_PARAMS.get("min_fill_ratio", 0.5))

    buf = np.array(BUFFERS[col_name], dtype=float)
    n = len(buf)

    if policy == "wait" and n < window_size:
        # ì˜ˆì¸¡ì€ ìƒìœ„ì—ì„œ None ì²˜ë¦¬, ì—¬ê¸°ì„  ì›ì‹œ ìµœì‹ ê°’ ë°˜í™˜
        return float(buf[-1]) if n > 0 else 0.0

    if policy == "passthrough" and n < window_size:
        return float(buf[-1]) if n > 0 else 0.0

    if policy == "ratio" and n < max(1, int(window_size * ratio)):
        return float(buf[-1]) if n > 0 else 0.0

    # ì›¨ì´ë¸Œë › ì ìš© (ë¶€ì¡±í•˜ë©´ edge íŒ¨ë”©)
    if n < window_size:
        if n == 0:
            x = np.zeros(window_size, dtype=float)
        else:
            x = np.pad(buf, (0, window_size - n), mode="edge")
    else:
        x = buf[-window_size:]

    y = _wavelet_denoise_window(x, col_name)
    return float(y[-1])


# -------------------------------
# ì˜ˆì¸¡ ì§„ì…ì 
# -------------------------------
def run_prediction(data: schemas.SensorInput) -> Tuple[Optional[int], list, list]:
    """
    ìˆœì„œ(í•™ìŠµê³¼ ë™ì¼): Hard-Iron â†’ Soft-Iron â†’ Windowed Wavelet â†’ Scaler â†’ MLP
    warmup_policy == 'wait' ì¼ ë•Œ ë²„í¼ ë¯¸ì¶©ë¶„ì´ë©´ (None, [], []) ë°˜í™˜
    """
    if not MODEL_LOADED:
        raise RuntimeError("Model components are not loaded properly.")

    # 1) ì…ë ¥
    sample = {
        "Mag_X": float(getattr(data, "Mag_X")),
        "Mag_Y": float(getattr(data, "Mag_Y")),
        "Mag_Z": float(getattr(data, "Mag_Z")),
        "Ori_X": float(getattr(data, "Ori_X")),
        "Ori_Y": float(getattr(data, "Ori_Y")),
        "Ori_Z": float(getattr(data, "Ori_Z")),
    }

    # 2) Hard-Iron
    for c in MAG_COLS:
        sample[c] = sample[c] - float(models["hard_iron"][c])

    # 3) Soft-Iron (ì„ í˜•)
    mag_vec = np.array([sample["Mag_X"], sample["Mag_Y"], sample["Mag_Z"]], dtype=float)
    mag_vec = models["soft_iron"] @ mag_vec
    sample["Mag_X"], sample["Mag_Y"], sample["Mag_Z"] = mag_vec.tolist()

    # 4) ë²„í¼ ì—…ë°ì´íŠ¸
    for c in MAG_COLS:
        BUFFERS[c].append(sample[c])

    # 5) warmup ì •ì±… í™•ì¸
    window_size = int(PREPROC_PARAMS["window_size"])
    policy = PREPROC_PARAMS.get("warmup_policy", "pad")
    n_now = min(len(BUFFERS[c]) for c in MAG_COLS)

    # 6) ì›¨ì´ë¸Œë ›(ìœˆë„ìš°) â†’ ìµœì‹  ìƒ˜í”Œ
    latest = {c: _latest_value_with_warmup(c) for c in MAG_COLS}

    # wait ì •ì±…ì´ë©´ ë²„í¼ ê½‰ ì°¨ê¸° ì „ ì˜ˆì¸¡ ë°˜í™˜í•˜ì§€ ì•ŠìŒ
    if policy == "wait" and n_now < window_size:
        return None, [], []

    # 7) íŠ¹ì§• ë²¡í„° (í•™ìŠµê³¼ ë™ì¼ ìˆœì„œ)
    feature_vec = np.array([
        latest["Mag_X"], latest["Mag_Y"], latest["Mag_Z"],
        sample["Ori_X"], sample["Ori_Y"], sample["Ori_Z"],
    ]).reshape(1, -1)

    # 8) ìŠ¤ì¼€ì¼ëŸ¬
    scaled = models["scaler"].transform(feature_vec)

    # 9) ì˜ˆì¸¡
    mlp = models["mlp"]
    pred_idx = mlp.predict(scaled)[0]

    raw_pred = models["label_encoder"].inverse_transform([pred_idx])[0]
    final_pred = extract_location_id(raw_pred)

    # 10) Top-3 (ì„œë¡œ ë‹¤ë¥¸ location_id ê¸°ì¤€)
    top_results_for_logging, top_results_for_response = [], []
    if hasattr(mlp, "predict_proba"):
        proba = mlp.predict_proba(scaled)[0]
        num_candidates = min(len(proba), 15)
        top_indices = np.argsort(-proba)[:num_candidates]
        raw_top = models["label_encoder"].inverse_transform(top_indices)
        top_probs = proba[top_indices]

        seen = set()
        uniq = []
        for lbl, p in zip(raw_top, top_probs):
            loc = extract_location_id(lbl)
            if loc not in seen:
                seen.add(loc)
                uniq.append((loc, float(p)))
                if len(uniq) >= 3:
                    break
        while len(uniq) < 3:
            uniq.append((0, 0.0))

        top_results_for_logging = uniq[:3]
        top_results_for_response = uniq[:3]

    return final_pred, top_results_for_logging, top_results_for_response
