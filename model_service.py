# -*- coding: utf-8 -*-
# ì´ íŒŒì¼ì€ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ë¡œë”© ë° ì˜ˆì¸¡ ë¡œì§ì„ ì „ë‹´í•©ë‹ˆë‹¤.

import os
import joblib
import numpy as np
import pandas as pd
from typing import Tuple

# app.pyê°€ ì•„ë‹Œ ì—¬ê¸°ì„œ ì§ì ‘ schemasë¥¼ importí•©ë‹ˆë‹¤.
import schemas

# --- ëª¨ë¸/ì „ì²˜ë¦¬ê¸° íŒŒì¼ì„ ëª¨ë‘ ë¡œë“œ ---
base_dir = os.path.dirname(__file__)
model_dir = os.path.join(base_dir, "model")

MODEL_PATHS = {
    "pipeline": os.path.join(model_dir, "mlp_pipeline_6input_magabs.pkl"),
    "label_encoder": os.path.join(model_dir, "label_encoder_6input.pkl"),
    "zero_center": os.path.join(model_dir, "zero_center_means.pkl"),
    "soft_iron": os.path.join(model_dir, "soft_iron_matrix.pkl"),
    "hard_iron": os.path.join(model_dir, "bias.pkl")
}

models = {}
MODEL_LOADED = False
FEATURE_COLS = None
try:
    for name, path in MODEL_PATHS.items():
        models[name] = joblib.load(path)
        print(f"âœ… ëª¨ë¸ ì»´í¬ë„ŒíŠ¸ ë¡œë“œ ì™„ë£Œ: {os.path.basename(path)}")
    MODEL_LOADED = True
    FEATURE_COLS = ['Mag_X', 'Mag_Y', 'Mag_Z', 'Ori_X', 'Ori_Y', 'Ori_Z', 'Mag_abs']
    print("ðŸš€ ëª¨ë“  ëª¨ë¸ ì»´í¬ë„ŒíŠ¸(7-input Pipeline)ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
except (FileNotFoundError, KeyError) as e:
    print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")

# --- ì™¸ë¶€(app.py)ì—ì„œ ì‚¬ìš©í•  í•¨ìˆ˜ë“¤ ---

def get_model_status() -> dict:
    """ëª¨ë¸ì˜ ë¡œë“œ ìƒíƒœì™€ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return {
        "status": "ok" if MODEL_LOADED else "error",
        "model_loaded": MODEL_LOADED,
        "model_name": "MLP 7-input Pipeline (with Full Calibration)",
        "feature_cols": FEATURE_COLS if MODEL_LOADED else None,
    }

def extract_location_id(label_str):
    """ë¼ë²¨ì—ì„œ ìœ„ì¹˜ IDë§Œ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ (ê¸°ì¡´ê³¼ ë™ì¼)"""
    try:
        return int(str(label_str).split('_')[0])
    except (ValueError, IndexError):
        try:
            return int(label_str)
        except:
            return 0

def run_prediction(data: schemas.SensorInput) -> Tuple[int, list, list]:
    """
    (ìˆ˜ì •) Mag_absë¥¼ ë³´ì • ì „ì— ë¨¼ì € ê³„ì‚°í•˜ë„ë¡ ë¡œì§ ìˆœì„œ ë³€ê²½
    """
    if not MODEL_LOADED:
        raise RuntimeError("Model components are not loaded properly.")

    # 1. ìž…ë ¥ ë°ì´í„°ë¥¼ Pandas DataFrameìœ¼ë¡œ ë³€í™˜
    initial_feature_cols = ['Mag_X', 'Mag_Y', 'Mag_Z', 'Ori_X', 'Ori_Y', 'Ori_Z']
    feature_df = pd.DataFrame([data.model_dump()], columns=initial_feature_cols)

    # (ìˆ˜ì • âœ¨) 2. ìžê¸°ìž¥ í¬ê¸°(Mag_abs)ë¥¼ "ë³´ì • ì „" ì›ë³¸ ê°’ìœ¼ë¡œ ë¨¼ì € ê³„ì‚°
    feature_df['Mag_abs'] = np.sqrt(feature_df['Mag_X']**2 + feature_df['Mag_Y']**2 + feature_df['Mag_Z']**2)

    # 3. Hard-Iron ë³´ì • (ì´í›„ ê³¼ì •ì€ ê¸°ì¡´ê³¼ ë™ì¼)
    for col in ['Mag_X', 'Mag_Y', 'Mag_Z']:
        feature_df[col] -= models["hard_iron"][col]

    # 4. Soft-Iron ë³´ì •
    mag_data = feature_df[['Mag_X', 'Mag_Y', 'Mag_Z']].values
    feature_df[['Mag_X', 'Mag_Y', 'Mag_Z']] = np.dot(mag_data, models["soft_iron"].T)
    
    # 5. Zero-Centering
    for col in initial_feature_cols:
        feature_df[col] -= models["zero_center"][col]
    
    # 6. íŒŒì´í”„ë¼ì¸ì„ ì‚¬ìš©í•œ ì˜ˆì¸¡
    pipeline = models["pipeline"]
    final_features_df = feature_df[FEATURE_COLS]
    prediction_index = pipeline.predict(final_features_df)[0]
    
    # ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼ì—ì„œ ì ‘ë¯¸ì‚¬ ì œê±°
    raw_prediction = models["label_encoder"].inverse_transform([prediction_index])[0]
    final_prediction = extract_location_id(raw_prediction)

    # 7. ì‹ ë¢°ë„ ë° Top-3 ê³„ì‚°
    top_results_for_logging, top_results_for_response = [], []
    
    if hasattr(pipeline, "predict_proba"):
        probabilities = pipeline.predict_proba(final_features_df)[0]
        num_candidates = min(len(probabilities), 15)
        top_indices = np.argsort(-probabilities)[:num_candidates]
        raw_top_labels = models["label_encoder"].inverse_transform(top_indices)
        top_probs = probabilities[top_indices]
        
        seen_locations = set()
        unique_results = []
        
        for raw_label, prob in zip(raw_top_labels, top_probs):
            location_id = extract_location_id(raw_label)
            if location_id not in seen_locations:
                seen_locations.add(location_id)
                unique_results.append((location_id, float(prob)))
                if len(unique_results) >= 3:
                    break
        
        while len(unique_results) < 3:
            unique_results.append((0, 0.0))
        
        top_results_for_logging = unique_results[:3]
        top_results_for_response = unique_results[:3]
        
    return final_prediction, top_results_for_logging, top_results_for_response